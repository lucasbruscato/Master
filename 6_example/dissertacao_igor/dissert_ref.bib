%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Lauro Cesar Araujo at 2013-08-21 10:57:09 -0300


%% Saved with string encoding Unicode (UTF-8)

@article{Lundstrom2016,
abstract = {A system for detecting deviating human behaviour in a smart home environment is the long-term goal of this work. Clearly, such systems will be very important in ambient assisted living services. A new approach to modelling human behaviour patterns is suggested in this paper. The approach reveals promising results in unsupervised modelling of human behaviour and detection of deviations by using such a model. Human behaviour/activity in a short time interval is represented in a novel fashion by responses of simple non-intrusive sensors. Deviating behaviour is revealed through data clustering and analysis of associations between clusters and data vectors representing adjacent time intervals (analysing transitions between clusters). To obtain clusters of human behaviour patterns, first, a random forest is trained without using beforehand defined teacher signals. Then information collected in the random forest data proximity matrix is mapped onto the 2D space and data clusters are revealed there by agglomerative clustering. Transitions between clusters are modelled by the third order Markov chain. Three types of deviations are considered: deviation in time, deviation in space and deviation in the transition between clusters of similar behaviour patterns. The proposed modelling approach does not make any assumptions about the position, type, and relationship of sensors but is nevertheless able to successfully create and use a model for deviation detection-this is claimed as a significant result in the area of expert and intelligent systems. Results show that spatial and temporal deviations can be revealed through analysis of a 2D map of high dimensional data. It is demonstrated that such a map is stable in terms of the number of clusters formed. We show that the data clusters can be understood/explored by finding the most important variables and by analysing the structure of the most representative tree.},
author = {Lundstr{\"{o}}m, Jens and J{\"{a}}rpe, Eric and Verikas, Antanas},
doi = {10.1016/j.eswa.2016.02.030},
file = {:home/igor/Downloads/1-s2.0-S0957417416300616-main.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Ambient assisted living,Intelligent environments,Markov chain,Random forests,Stochastic neighbour embedding},
mendeley-groups = {TCC},
pages = {429--440},
title = {{Detecting and exploring deviating behaviour of smart home residents}},
volume = {55},
year = {2016}
}

@article{Mozer1998,
abstract = {Although the prospect of computerized homes has a long history, ho/ne automation has never become terribly popular because the benefits are seldom seen to outweigh the costs. One significant cost of an automated home is that someone has to program it to behave appropriately. Typical inhabit- ants do not want to program simple devices such as VCRs, let alone a much broader range of electronic devices, appli- ances, and comfort systems that have even greater function- ality. We describe an alternative approach t in which the goal is for the home to essentially program itself by observing the lifestyle and desires of the inhabitants, and learning to antic- ipate and accommodate their needs. The system we have developed controls basic residential comfort systems--air heating, lighting, ventilation, and water heating. We have constructed a prototype system in an actual residence, and describe initial results and the current state of the project.},
author = {Mozer, Michael C},
doi = {SS-98-02/SS98-02-017},
journal = {American Association for Artificial Intelligence Spring Symposium on Intelligent Environments},
keywords = {110-114,1998,aaai press,an environment that adapts,association for artificial intelligence,ca,coen,ears in,ed,m,menlo park,on intelligent environments,pp,proceedings of the american,spring symposium,the neural network house,to its inhabitants},
mendeley-groups = {TCC},
number = {December},
pages = {110--114},
title = {{The neural network house: An environment that adapts to its inhabitants}},
year = {1998}
}

@article{OASIS2014,
abstract = {MQTT is a Client Server publish/subscribe messaging transport protocol. It is light weight, open, simple, and designed so as to be easy to implement. These characteristics make it ideal for use in many situations, including constrained environments such as for communication in Machine to Machine (M2M) and Internet of Things (IoT) contexts where a small code footprint is required and/or network bandwidth is at a premium. The protocol runs over TCP/IP, or over other network protocols that provide ordered, lossless, bi- directional connections. Its features include: Use of the publish/subscribe message pattern which provides one-to-many message distribution and decoupling of applications. A messaging transport that is agnostic to the content of the payload. Three qualities of service for message delivery: mqtt-v3.1.1-os 29 October 2014 Standards Track Work Product Copyright {\textcopyright} OASIS Open 2014. All Rights Reserved. Page 2 of 81 "At most once", where messages are delivered according to the best efforts of the operating environment. Message loss can occur. This level could be used, for example, with ambient sensor data where it does not matter if an individual reading is lost as the next one will be published soon after. "At least once", where messages are assured to arrive but duplicates can occur. "Exactly once", where message are assured to arrive exactly once. This level could be used, for example, with billing systems where duplicate or lost messages could lead to incorrect charges being applied. A small transport overhead and protocol exchanges minimized to reduce network traffic. A mechanism to notify interested parties when an abnormal disconnection occurs.},
organization = {OASIS},
journal = {OASIS Standard},
mendeley-groups = {TCC},
number = {October},
pages = {81},
title = {{MQTT Version 3.1.1}},
url = {http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html},
year = {2014}
}

@misc{carr1987home,
	annote = {US Patent 4,644,320},
	author = {Carr, R S and Dalzell, J N and Holmes, J F and Hunt, J M},
	mendeley-groups = {TCC},
	publisher = {Google Patents},
	title = {{Home energy monitoring and control system}},
	url = {https://www.google.com/patents/US4644320},
	year = {1987}
}

@article{Hunt1986,
	abstract = {Homeowners are often frustrated in trying to understand and control their use of electrical energy. It is difficult to determine from the monthly utility bill which appliances consume the most energy or if a change in habits would significantly affect energy use. What is needed is a device that can conveniently measure, display and control the energy used by various appliances in the home. Energy monitoring and control systems for commercial buildings are now commonplace. However, they have been too expensive and complicated for the residential market. The home system described in this paper is sophisticated in performance, but designed to be economical and very easy to use. The cost per function has been made low by combining several functions in one unit: thermostat, energy monitor and display, and remote control system. The system consists of a master unit and various slave units (see Figure 1). The master unit may be plugged into any outlet in the house and moved at will. It is about the size of a desk telephone (see Figure 2). It controls the slave units which are placed near the appliances to be monitored. A 120 V portable slave unit is shown in Figure 3.},
	author = {Hunt, Jm and Holmes, Jf},
	journal = {IEEE Transactions on Consumer Electronics},
	mendeley-groups = {TCC},
	number = {3},
	pages = {578--583},
	title = {{Electrical Energy Monitoring and Control System for the Home}},
	url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4071441},
	volume = {C},
	year = {1986}
}

@article{Mozer2007,
	abstract = {I present a general taxonomy of neural net architectures for processing time-varying patterns. This taxonomy subsumes many existing architectures in the literature, and points to several promising architectures that have yet to be examined. Any architecture that processes time- varying patterns requires two conceptually distinct components: a short-term memory that holds on to relevant past events and an associator that uses the short-term memory to classify or predict. My taxonomy is based on a characterization of short-term memory models along the dimensions of form, content, and adaptability. Experiments on predicting future values of a financial time series (US dollarâ€“Swiss franc exchange rates) are presented using several alternative memory models. The results of these experiments serve as a baseline against which more sophisticated architectures can be compared.},
	author = {Mozer, Michael C},
	journal = {Predicting the future and understanding the past},
	mendeley-groups = {TCC},
	pages = {243--264},
	title = {{Neural net architectures for temporal sequence processing}},
	year = {2007}
}

@article{Ludermir1999,
	author = {Ludermir, Teresa B and Carvalho, Andr{\'{e}} De and Braga, Ant{\^{o}}nio De P{\'{a}}dua and Souto, Marc{\'{i}}lio C P De},
	journal = {Neural Computing Surveys},
	mendeley-groups = {TCC},
	pages = {41--61},
	title = {{Weightless neural models: a review of current and past works}},
	volume = {2},
	year = {1999}
}

@article{Tarling1993, 
	author={R. Tarling and R. Rohwer}, 
	journal={Electronics Letters}, 
	title={Efficient use of training data in the n-tuple recognition method}, 
	year={1993}, 
	volume={29}, 
	number={24}, 
	pages={2093-2094}, 
	keywords={character recognition;pattern recognition;architectural parameters;character recognition;n-tuple recognition method;robustness;saturation problem;training data}, 
	doi={10.1049/el:19931398}, 
	ISSN={0013-5194}, 
	month={Nov}}

@article{Rashidi2013,
	abstract = {The increasing aging population in the coming decades will result in many complications for society and in particular for the healthcare system due to the shortage of healthcare professionals and healthcare facilities. To remedy this problem, researchers have pursued developing remote monitoring systems and assisted living technologies by utilizing recent advances in sensor and networking technology, as well as in the data mining and machine learning fields. In this article, we report on our fully automated approach for discovering and monitoring patterns of daily activities. Discovering and tracking patterns of daily activities can provide unprecedented opportunities for health monitoring and assisted living applications, especially for older adults and individuals with mental disabilities. Previous approaches usually rely on preselected activities or labeled data to track and monitor daily activities. In this article, we present a fully automated approach by discovering natural activity patterns and their variations in real-life data. We will show how our activity discovery component can be integrated with an activity recognition component to track and monitor various daily activity patterns. We also provide an activity visualization component to allow caregivers to visually observe and examine the activity patterns using a user-friendly interface. We validate our algorithms using real-life data obtained from two apartments during a three-month period. Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications -- Data mining; 1.2.6 [Artificial Intelligence]: Learning; H.4.m [Information Systems Applications]: Miscellaneous General Terms: Design, Experimentation, Algorithms [ABSTRACT FROM AUTHOR]},
	archivePrefix = {arXiv},
	arxivId = {1005.3014},
	author = {Rashidi, Parisa and Cook, Diane J},
	doi = {10.1145/2508037.2508045},
	eprint = {1005.3014},
	isbn = {9781627480031},
	issn = {21576904},
	journal = {ACM Transactions on Intelligent Systems {\&} Technology},
	keywords = {Assisted living technology,DATA mining,HEALTH facilities,HOME care services,HUMAN activity recognition,OLDER people -- Care,PATTERN recognition systems,health monitoring,sequence mining,smart environments},
	mendeley-groups = {TCC},
	number = {4},
	pages = {64--64:20},
	title = {{COM: A Method for Mining and Monitoring Human Activity Patterns in Home-Based Health Monitoring Systems.}},
	url = {10.1145/2508037.2508045},
	volume = {4},
	year = {2013}
}

@inproceedings{Cook2009,
	abstract = {OBJECTIVES: Pervasive computing technology can provide valuable health monitoring and assistance technology to help individuals live independent lives in their own homes. As a critical part of this technology, our objective is to design software algorithms that recognize and assess the consistency of activities of daily living that individuals perform in their own homes. METHODS: We have designed algorithms that automatically learn Markov models for each class of activity. These models are used to recognize activities that are performed in a smart home and to identify errors and inconsistencies in the performed activity. RESULTS: We validate our approach using data collected from 60 volunteers who performed a series of activities in our smart apartment testbed. The results indicate that the algorithms correctly label the activities and successfully assess the completeness and consistency of the performed task. CONCLUSIONS: Our results indicate that activity recognition and assessment can be automated using machine learning algorithms and smart home technology. These algorithms will be useful for automating remote health monitoring and interventions.},
	author = {Cook, D. J. and Schmitter-Edgecombe, M.},
	booktitle = {Methods of Information in Medicine},
	doi = {10.3414/ME0592},
	isbn = {1000341380},
	issn = {00261270},
	keywords = {Activities of daily living,Activity recognition,Health monitoring,Machine learning,Smart homes},
	mendeley-groups = {TCC},
	number = {5},
	pages = {480--485},
	pmid = {19448886},
	title = {{Assessing the quality of activities in a smart environment}},
	volume = {48},
	year = {2009}
}

@article{Xing2010,
	abstract = {Sequence classification has a broad range of applications such as genomic analysis, information retrieval, health informatics, finance, and abnormal detection. Different from the classification task on feature vectors, sequences do not have explicit features. Even with sophisticated feature selection techniques, the dimensionality of potential features may still be very high and the sequential nature of features is difficult to capture. This makes sequence classification a more challenging task than classification on feature vectors. In this paper, we present a brief review of the existing work on sequence classification. We summarize the sequence classification in terms of methodologies and application domains. We also provide a review on several extensions of the sequence classification problem, such as early classification on sequences and semi-supervised learning on sequences.},
	author = {Xing, Zhengzheng and Pei, Jian and Keogh, Eamonn},
	doi = {10.1145/1882471.1882478},
	isbn = {1931-0145},
	issn = {19310145},
	journal = {ACM SIGKDD Explorations Newsletter},
	keywords = {classification,rief survey on sequence,school of computing science,simon fraser university},
	mendeley-groups = {TCC},
	number = {1},
	pages = {40},
	title = {{A brief survey on sequence classification}},
	volume = {12},
	year = {2010}
}

@online{HMMPict,
	Organization  = "user Tdunning / Wikimedia Commons",
	title   = "Hidden Markov Model",
	year    = "2012",
	urlseen = "18-11-16",
	url     = "https://commons.wikimedia.org/w/index.php?curid=18125206",
}

@online{BoxLab,
	Organization  = "Massachussets Institute of Technology",
	title   = "Development of Longitudinal Home Activity Datasets as a Shared Resource",
	year    = "2005",
	urlseen = "18-11-16",
	url     = "https://boxlab.wikispaces.com/",
}

@misc{GHAHRAMANI2001,
	abstract = {We provide a tutorial on learning and inference in hidden Markov models in the context of the recent literature on Bayesian networks. This perspective makes it possible to consider novel generalizations of hidden Markov models with multiple hidden state variables, multiscale representations, and mixed discrete and continuous variables. Although exact inference in these generalizations is usually intractable, one can use approximate inference algorithms such as Markov chain sampling and variational methods. We describe how such methods are applied to these generalized hidden Markov models. We conclude this review with a discussion of Bayesian methods for model selection in generalized HMMs.},
	author = {GHAHRAMANI, ZOUBIN},
	booktitle = {International Journal of Pattern Recognition and Artificial Intelligence},
	doi = {10.1142/S0218001401000836},
	isbn = {981-02-4564-5},
	issn = {0218-0014},
	number = {01},
	pages = {9--42},
	pmid = {18428778},
	title = {{AN INTRODUCTION TO HIDDEN MARKOV MODELS AND BAYESIAN NETWORKS}},
	volume = {15},
	year = {2001}
}

@article{de2012state,
  title={State of the art of smart homes},
  author={De Silva, Liyanage C and Morikawa, Chamin and Petra, Iskandar M},
  journal={Engineering Applications of Artificial Intelligence},
  volume={25},
  number={7},
  pages={1313--1321},
  year={2012},
  publisher={Elsevier}
}

@phdthesis{Torres2016,
author = {Torres, Luiz Carlos Bambirra},
school = {Universidade Federal de Minas Gerais},
title = {{Classificador por Arestas de Suporte (CLAS): M{\'{e}}todos de Aprendizado Baseados em Grafos de Gabriel}},
year = {2016}
}

@book{Duda2000,
abstract = {The first edition, published in 1973, has become a classic reference in the field. Now with the second edition, readers will find information on key new topics such as neural networks and statistical pattern recognition, the theory of machine learning, and the theory of invariances. Also included are worked examples, comparisons between different methods, extensive graphics, expanded exercises and computer project topics.},
author = {Duda, R O and Hart, P E and Stork, D G},
booktitle = {New York: John Wiley, Section},
doi = {10.1038/npp.2011.9},
isbn = {978-0-471-05669-0},
issn = {1740634X},
pages = {654},
pmid = {21346736},
title = {{Pattern Classification}},
year = {2000}
}

@article{Weinberger2009,
abstract = {The accuracy of k-nearest neighbor (kNN) classification depends significantly on the metric used to compute distances between different examples. In this paper, we show how to learn a Mahalanobis distance metric for kNN classification from labeled examples. The Mahalanobis metric can equivalently be viewed as a global linear transformation of the input space that precedes kNN classification using Euclidean distances. In our approach, the metric is trained with the goal that the k-nearest neighbors always belong to the same class while examples from different classes are separated by a large margin. As in support vector machines (SVMs), the margin criterion leads to a convex optimization based on the hinge loss. Unlike learning in SVMs, however, our approach requires no modification or extension for problems in multiway (as opposed to binary) classification. In our framework, the Mahalanobis distance metric is obtained as the solution to a semidefinite program. On several data sets of varying size and difficulty, we find that metrics trained in this way lead to significant improvements in kNN classification. Sometimes these results can be further improved by clustering the training examples and learning an individual metric within each cluster. We show how to learn and combine these local metrics in a globally integrated manner.},
archivePrefix = {arXiv},
arxivId = {1407.4979},
author = {Weinberger, Kilian Q and Saul, Lawrence K},
doi = {10.1126/science.277.5323.215},
eprint = {1407.4979},
isbn = {1532-4435},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
keywords = {Metric learning,convex optimization,ing,mahalanobis distance,metric learn-,multi-class classification,semi-definite programming,support vector machines},
pages = {207--244},
pmid = {17490632},
title = {{Distance Metric Learning for Large Margin Nearest Neighbor Classification}},
volume = {10},
year = {2009}
}

@article{Demsar2006,
abstract = {While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Dem{\v{s}}ar, Janez},
doi = {10.1016/j.jecp.2010.03.005},
eprint = {arXiv:1011.1669v3},
isbn = {9781424450404},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {Friedman test,Wilcoxon signed ranks test,comparative studies,multiple comparisons tests,statistical methods},
pages = {1--30},
pmid = {20451214},
title = {{Statistical Comparisons of Classifiers over Multiple Data Sets}},
volume = {7},
year = {2006}
}

@article{Coelho2015,
abstract = {{\textcopyright} 2015 The Institution of Engineering and Technology.A new learning method for classification problems that is suitable for integrated circuit implementation is presented. The method, which outperforms current approaches in many data sets, is based on a structural description of the learning set represented by a planar graph. The final classification function is composed of a hierarchical mixture of local experts, which yields a large margin classifier for the whole learning set. Since it is based only on distance calculations, on-chip learning can also be executed. The method is also appropriate for online and incremental learning, since model parameters are obtained directly from the data set, without need of user interaction for learning.},
author = {Torres, L.C.B. and Castro, C.L. and Coelho, F. and {Sill Torres}, F. and Braga, A.P.},
doi = {10.1049/el.2015.1644},
issn = {0013-5194},
journal = {Electronics Letters},
number = {24},
pages = {1967--1969},
pmid = {1000363188},
title = {{Distance-based large margin classifier suitable for integrated circuit implementation}},
volume = {51},
year = {2015}
}

@article{Torres2012,
author = {Torres, L.C.B. and Castro, C.L. and Braga, A.P.},
journal = {International Conference on Artificial Neural Networks},
number = {22},
title = {{A Computational Geometry Approach for Pareto-Optimal Selection of Neural Networks}},
year = {2012}
}

@article{Cortes1995,
abstract = {The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very highdimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Cortes, Corinna and Vapnik, Vladimir},
doi = {10.1023/A:1022627411411},
eprint = {arXiv:1011.1669v3},
isbn = {0885-6125},
issn = {15730565},
journal = {Machine Learning},
keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
number = {3},
pages = {273--297},
pmid = {19549084},
title = {{Support-Vector Networks}},
volume = {20},
year = {1995}
}

@article{Torres2015,
author = {Torres, L.C.B. and Castro, C.L. and Braga, A.P.},
journal = {International Joint Conference on Neural Networks },
title = {{A Parameterless Mixture Model for Large Margin Classification}},
year = {2015}
}

@article{Kohavi1995,
abstract = {We review accuracy estimation methods and compare the two most common methods: cross-validation and bootstrap. Recent experimen-tal results on artiicial data and theoretical re-sults in restricted settings have shown that for selecting a good classiier from a set of classi-(model selection), ten-fold cross-validation may be better than the more expensive l e a ve-one-out cross-validation. We report on a large-scale experiment|over half a million runs of C4.5 and a Naive-Bayes algorithm|to estimate the eeects of diierent parameters on these al-gorithms on real-world datasets. For cross-validation, we v ary the number of folds and whether the folds are stratiied or nott for boot-strap, we v ary the number of bootstrap sam-ples. Our results indicate that for real-word datasets similar to ours, the best method to use for model selection is ten-fold stratiied cross validation, even if computation power allows using more folds.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Kohavi, Ron},
journal = {Proceedings of the 14th International Joint Conference on Articial Intelligence (IJCAI)},
doi = {10.1067/mod.2000.109031},
eprint = {arXiv:1011.1669v3},
isbn = {1-55860-363-8},
issn = {10450823},
pages = {1137-1145},
pmid = {11029742},
title = {{A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection}},
year = {1995}
}

@article{Albuquerque2000,
abstract = {This paper presents a new learning scheme for improving generalization of multilayer perceptrons. The algorithm uses a multi-objective optimization approach to balance between the error of the training data and the norm of network weight vectors to avoid overfitting. The results are compared with support vector machines and standard backpropagation. (C) 2000 Elsevier Science B.V. All rights reserved.},
author = {de {Albuquerque Teixeira}, Roselito and Braga, Ant{\^{o}}nio P{\'{a}}dua and Takahashi, Ricardo H C and Saldanha, Rodney R.},
doi = {10.1016/S0925-2312(00)00327-1},
isbn = {5531499485},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Generalization,Learning,Multi-objective optimization},
pages = {189--194},
title = {{Improving generalization of MLPs with multi-objective optimization}},
volume = {35},
year = {2000}
}

@article{Gabriel1969,
abstract = {The authors discuss the problems of describing geographic variation data and develop statistical methods for categorizing sets of populations sampled from different localities. The general approach of the simultaneous test procedures, available with a variety of statistical tests and for continuous as well as for categorical data, is employed with these techniques. Geographical regions are defined as sets of connected localities, with connectedness being defined geometrically. Maximal acceptable connected sets of localities (defined as regions) or coarsest acceptable connected partitions of the entire set of localities are found by these procedures. These are illustrated with several examples.},
author = {Gabriel, K. Ruben and Sokal, Robert R.},
doi = {10.2307/2412323},
isbn = {00397989},
issn = {00397989},
journal = {Systematic Zoology},
number = {3},
pages = {259--278},
title = {{A New Statistical Approach to Geographic Variation Analysis}},
url = {http://sysbio.oxfordjournals.org/cgi/content/abstract/18/3/259},
volume = {18},
year = {1969}
}

@misc{UCI,
abstract = {The UCI Machine Learning Repository is a collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms. The archive was created as an ftp archive in 1987 by David Aha and fellow graduate students at UC Irvine. Since that time, it has been widely used by students, educators, and researchers all over the world as a primary source of machine learning data sets. As an indication of the impact of the archive, it has been cited over 1000 times, making it one of the top 100 most cited "papers" in all of computer science. The current version of the web site was designed in 2007 by Arthur Asuncion and David Newman, and this project is in collaboration with Rexa.info at the University of Massachusetts Amherst. Funding support from the National Science Foundation is gratefully acknowledged.},
author = {Bache, K. and Lichman, M.},
booktitle = {University of California Irvine School of Information},
doi = {University of California, Irvine, School of Information and Computer Sciences},
isbn = {{\textless}null{\textgreater}},
number = {14/8},
pages = {0},
title = {{UCI Machine Learning Repository}},
url = {http://www.ics.uci.edu/{~}mlearn/MLRepository.html},
year = {2013}
}

@article{Golub1999,
abstract = {In the clinical context, samples assayed by microarray are often classified by cell line or tumour type and it is of interest to discover a set of genes that can be used as class predictors. The leukemia dataset of Golub et al. [1] and the NCI60 dataset of Ross et al. [2] present multiclass classification problems where three tumour types and nine cell lines respectively must be identified. We apply an evolutionary algorithm to identify the near-optimal set of predictive genes that classify the data. We also examine the initial gene selection step whereby the most informative genes are selected from the genes assayed. In the absence of feature selection, classification accuracy on the training data is typically good, but not replicated on the testing data. Gene selection using the RankGene software [3] is shown to significantly improve performance on the testing data. Further, we show that the choice of feature selection criteria can have a significant effect on accuracy. The evolutionary algorithm is shown to perform stably across the space of possible parameter settings â€“ indicating the robustness of the approach. We assess performance using a low variance estimation technique, and present an analysis of the genes most often selected as predictors. The computational methods we have developed perform robustly and accurately, and yield results in accord with clinical knowledge: A Z-score analysis of the genes most frequently selected identifies genes known to discriminate AML and Pre-T ALL leukemia. This study also confirms that significantly different sets of genes are found to be most discriminatory as the sample classes are refined.},
author = {Golub, T. R.},
doi = {10.1126/science.286.5439.531},
isbn = {0036-8075 (Print)$\backslash$r0036-8075 (Linking)},
issn = {00368075},
journal = {Science},
keywords = {Algorithms,Bioinformatics,Combinatorial Libraries,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
number = {5439},
pages = {531--537},
pmid = {10521349},
title = {{Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.286.5439.531},
volume = {286},
year = {1999}
}

@article{Hess2006,
abstract = {PURPOSE: We developed a multigene predictor of pathologic complete response (pCR) to preoperative weekly paclitaxel and fluorouracil-doxorubicin-cyclophosphamide (T/FAC) chemotherapy and assessed its predictive accuracy on independent cases. PATIENTS AND METHODS: One hundred thirty-three patients with stage I-III breast cancer were included. Pretreatment gene expression profiling was performed with oligonecleotide microarrays on fine-needle aspiration specimens. We developed predictors of pCR from 82 cases and assessed accuracy on 51 independent cases. RESULTS: Overall pCR rate was 26{\%} in both cohorts. In the training set, 56 probes were identified as differentially expressed between pCR versus residual disease, at a false discovery rate of 1{\%}. We examined the performance of 780 distinct classifiers (set of genes + prediction algorithm) in full cross-validation. Many predictors performed equally well. A nominally best 30-probe set Diagonal Linear Discriminant Analysis classifier was selected for independent validation. It showed significantly higher sensitivity (92{\%} v 61{\%}) than a clinical predictor including age, grade, and estrogen receptor status. The negative predictive value (96{\%} v 86{\%}) and area under the curve (0.877 v 0.811) were nominally better but not statistically significant. The combination of genomic and clinical information yielded a predictor not significantly different from the genomic predictor alone. In 31 samples, RNA was hybridized in replicate with resulting predictions that were 97{\%} concordant. CONCLUSION: A 30-probe set pharmacogenomic predictor predicted pCR to T/FAC chemotherapy with high sensitivity and negative predictive value. This test correctly identified all but one of the patients who achieved pCR (12 of 13 patients) and all but one of those who were predicted to have residual disease had residual cancer (27 of 28 patients).},
author = {Hess, Kenneth R. and Anderson, Keith and Symmans, W. Fraser and Valero, Vicente and Ibrahim, Nuhad and Mejia, Jaime A. and Booser, Daniel and Theriault, Richard L. and Buzdar, Aman U. and Dempsey, Peter J. and Rouzier, Roman and Sneige, Nour and Ross, Jeffrey S. and Vidaurre, Tatiana and Gomez, Henry L. and Hortobagyi, Gabriel N. and Pusztai, Lajos},
doi = {10.1200/JCO.2006.05.6861},
isbn = {1527-7755 (Electronic)},
issn = {0732183X},
journal = {Journal of Clinical Oncology},
number = {26},
pages = {4236--4244},
pmid = {16896004},
title = {{Pharmacogenomic predictor of sensitivity to preoperative chemotherapy with paclitaxel and fluorouracil, doxorubicin, and cyclophosphamide in breast cancer}},
volume = {24},
year = {2006}
}

@incollection{Torres2014,
abstract = {The RBF network is commonly used for classification and function approximation. The center and radius of the activation function of neurons is an important parameter to be found before the network training. This paper presents a method based on computational geometry to find these coefficients without any parameters provided by the user. The method is compared with a SVM and experimental results showed that our approach is promising. {\textcopyright} 2014 Springer International Publishing Switzerland.},
author = {Torres, L.C.B. and Lemos, A.P. and Castro, C.L. and Braga, A.P.},
booktitle = {Lecture Notes in Computer Science},
doi = {10.1007/978-3-319-11179-7_67},
isbn = {9783319111780},
issn = {16113349 03029743},
keywords = {[classification, gabriel graph, machine learning,},
title = {{A geometrical approach for parameter selection of radial basis functions networks}},
volume = {8681 LNCS},
year = {2014}
}

@article{Torres20152,
author = {Torres, L.C.B. and Castro, C.L. and Braga, A.P.},
isbn = {978-287587014-8},
journal = {Proceedings of the European Symposium on Neural Networks 2015},
pages = {237--242},
title = {{Gabriel Graph for Dataset Structure and Large Margin Classification: A Bayesian Approach}},
year = {2015}
}

@book{Vapnik2000,
abstract = {A very good high-level introduction in Statistical Learning Theory in the VC formulation, plus a comprehensive overview of the SV algorithm. First description of SV machines for regression estimation.},
author = {Vapnik, Vladimir Naumovich},
booktitle = {Springer},
doi = {10.1109/TNN.1997.641482},
isbn = {978-1-4419-3160-3},
issn = {10459227},
number = {6},
pages = {324},
pmid = {18255760},
title = {{The Nature of Statistical Learning Theory}},
volume = {8},
year = {2000}
}

@article{viterbi1967error,
  title={Error bounds for convolutional codes and an asymptotically optimum decoding algorithm},
  author={Viterbi, Andrew},
  journal={IEEE transactions on Information Theory},
  volume={13},
  number={2},
  pages={260--269},
  year={1967},
  publisher={IEEE}
}

@inproceedings{ghahramani1996factorial,
  title={Factorial hidden Markov models},
  author={Ghahramani, Zoubin and Jordan, Michael I},
  booktitle={Advances in Neural Information Processing Systems},
  pages={472--478},
  year={1996}
}