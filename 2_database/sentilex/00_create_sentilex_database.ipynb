{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and handle SentiLex-PT02 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "sentiLexDatabase = pd.read_csv(\"SentiLex-flex-PT02.txt\", header = None)\n",
    "sentiLexDatabase.columns = [\"adjective\", \"description\"]\n",
    "\n",
    "# extract \"polarity\" from \"description\"\n",
    "polarity = pd.DataFrame(sentiLexDatabase.description.str.split('\\;+').str[3].str.split('\\=+').str[1])\n",
    "sentiLexDatabase = pd.concat([sentiLexDatabase, polarity], axis = 1, join = 'outer')\n",
    "\n",
    "# remove duplicates\n",
    "sentiLexDatabase = sentiLexDatabase.iloc[:, [0, 2]].drop_duplicates()\n",
    "sentiLexDatabase.columns = [\"adjective\", \"polarity\"]\n",
    "\n",
    "# select only polarities in [-1, 0, 1]\n",
    "polarities = [\"-1\", \"0\", \"1\"]\n",
    "sentiLexDatabase = sentiLexDatabase[sentiLexDatabase.polarity.isin(polarities)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define randomly reports for improving SentiLex-PT02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import os.path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"ciclo_3\",\n",
    "           \"ciclo_4\",\n",
    "           \"edicoes_anteriores/sorteio_34\",\n",
    "           \"edicoes_anteriores/sorteio_35\",\n",
    "           \"edicoes_anteriores/sorteio_36\",\n",
    "           \"edicoes_anteriores/sorteio_37\",\n",
    "           \"edicoes_anteriores/sorteio_38\",\n",
    "           \"edicoes_anteriores/sorteio_39\",\n",
    "           \"edicoes_anteriores/sorteio_40\"]\n",
    "\n",
    "fileNamesAndPaths = []\n",
    "\n",
    "for folder in folders:\n",
    "    directory = '../programa_de_fiscalizacao_em_entes_federativos/' + folder\n",
    "    \n",
    "    numberOfFiles = len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))]) - 3\n",
    "    random.seed(7)\n",
    "    randomFileNumber = int(random.uniform(0, numberOfFiles))\n",
    "    \n",
    "    fileNameAndPath = directory + \"/\" + os.listdir(directory)[randomFileNumber]\n",
    "    fileNamesAndPaths.append(fileNameAndPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import reports, collect unique words and save words not in SentiLex-PT02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import PyPDF2\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of reports read to improve SentiLex database\n",
      "../programa_de_fiscalizacao_em_entes_federativos/ciclo_3/9037-Poço Branco-RN.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/ciclo_4/10321-Uruguaiana-RS.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_34/1837-São Mateus-ES.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_35/1906-Patrocínio-MG.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_36/2483-Pontal do Paraná-PR.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_37/2871-São José do Sul-RS.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_38/2975-Presidente Kennedy-ES.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_39/3179-São Domingos do Araguaia-PA.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_40/3390-Goianésia do Pará-PA.pdf\n"
     ]
    }
   ],
   "source": [
    "print(\"List of reports read to improve SentiLex database\")\n",
    "\n",
    "for fileNumber in range(0, len(fileNamesAndPaths)):\n",
    "    filename = fileNamesAndPaths[fileNumber]\n",
    "    print(filename)\n",
    "    \n",
    "    # create a pdf object\n",
    "    file = open(filename, 'rb')\n",
    "    \n",
    "    # create a pdf reader object\n",
    "    fileReader = PyPDF2.PdfFileReader(file)\n",
    "\n",
    "    # iterate all documents\n",
    "    wordIndex = -1\n",
    "    flagInAWord = 0\n",
    "    words = []\n",
    "\n",
    "    for i in range(fileReader.numPages):\n",
    "        page = unidecode.unidecode(fileReader.getPage(i).extractText().lower())\n",
    "\n",
    "        for j in range(len(page)):\n",
    "            letter = page[j]\n",
    "\n",
    "            if (not letter.isalpha()) and flagInAWord != 0:\n",
    "                flagInAWord = 0\n",
    "            elif letter.isalpha() and flagInAWord == 0:\n",
    "                flagInAWord = 1\n",
    "                wordIndex += 1\n",
    "                words.append(letter)\n",
    "            elif letter.isalpha() and flagInAWord != 0:\n",
    "                words[wordIndex] += letter\n",
    "\n",
    "    wordsUnique = pd.DataFrame(pd.DataFrame(words).iloc[:, 0].unique())\n",
    "    wordsUnique.columns = [\"adjective\"]\n",
    "\n",
    "    wordsWithPolarity = wordsUnique.merge(sentiLexDatabase, left_on = \"adjective\", right_on = \"adjective\", how = \"left\")\n",
    "    \n",
    "    wordsWithPolarity[wordsWithPolarity.polarity.isnull()].to_csv(\"improving_senti_lex/\" + folders[fileNumber].replace(\"/\", \"_\") + \".csv\",\n",
    "                                                              sep = ';',\n",
    "                                                              encoding = 'utf-8',\n",
    "                                                              index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiLexDatabase.to_csv(\"0_create_sentilex_database.csv\",\n",
    "                        sep = ';',\n",
    "                        encoding = 'utf-8',\n",
    "                        index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
