{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Initial SentiLex Database and Improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import PyPDF2\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read SentiLex-PT02 and extract polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "sentilex_database = pd.read_csv(\"SentiLex-flex-PT02.txt\", header = None)\n",
    "sentilex_database.columns = [\"adjective\", \"description\"]\n",
    "\n",
    "# extract \"polarity\" from \"description\"\n",
    "polarity = pd.DataFrame(sentilex_database.description.str.split('\\;+').str[3].str.split('\\=+').str[1])\n",
    "sentilex_database = pd.concat([sentilex_database, polarity], axis = 1, join = 'outer')\n",
    "\n",
    "# remove duplicates\n",
    "sentilex_database = sentilex_database.iloc[:, [0, 2]].drop_duplicates()\n",
    "sentilex_database.columns = [\"adjective\", \"polarity\"]\n",
    "\n",
    "# select only polarities in [-1, 0, 1]\n",
    "polarities = [\"-1\", \"0\", \"1\"]\n",
    "sentilex_database = sentilex_database[sentilex_database.polarity.isin(polarities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjective</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>à-vontade</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abafada</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abafadas</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abafado</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abafados</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adjective polarity\n",
       "0  à-vontade        1\n",
       "1    abafada       -1\n",
       "2   abafadas       -1\n",
       "3    abafado       -1\n",
       "4   abafados       -1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentilex_database.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save initial sentilex database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentilex_database.to_csv(\"99_create_initial_sentilex_database.csv\",\n",
    "                         sep = ';',\n",
    "                         encoding = 'utf-8',\n",
    "                         index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define randomly reports for improving SentiLex-PT02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../programa_de_fiscalizacao_em_entes_federativos/ciclo_3/9044-Putinga-RS.pdf',\n",
       " '../programa_de_fiscalizacao_em_entes_federativos/ciclo_4/10321-Uruguaiana-RS.pdf',\n",
       " '../programa_de_fiscalizacao_em_entes_federativos/ciclo_5/12311-Teresópolis-RJ.pdf',\n",
       " '../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_34/1837-São Mateus-ES.pdf',\n",
       " '../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_35/1906-Patrocínio-MG.pdf',\n",
       " '../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_36/2483-Pontal do Paraná-PR.pdf',\n",
       " '../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_37/2871-São José do Sul-RS.pdf',\n",
       " '../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_38/2975-Presidente Kennedy-ES.pdf',\n",
       " '../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_39/3179-São Domingos do Araguaia-PA.pdf',\n",
       " '../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_40/3390-Goianésia do Pará-PA.pdf']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [\"ciclo_3\",\n",
    "           \"ciclo_4\",\n",
    "           \"ciclo_5\",\n",
    "           \"edicoes_anteriores/sorteio_34\",\n",
    "           \"edicoes_anteriores/sorteio_35\",\n",
    "           \"edicoes_anteriores/sorteio_36\",\n",
    "           \"edicoes_anteriores/sorteio_37\",\n",
    "           \"edicoes_anteriores/sorteio_38\",\n",
    "           \"edicoes_anteriores/sorteio_39\",\n",
    "           \"edicoes_anteriores/sorteio_40\"]\n",
    "\n",
    "file_names_and_paths = []\n",
    "\n",
    "for folder in folders:\n",
    "    directory = '../programa_de_fiscalizacao_em_entes_federativos/' + folder\n",
    "    \n",
    "    number_of_files = len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))]) - 3\n",
    "    random.seed(7)\n",
    "    random_file_number = int(random.uniform(0, number_of_files))\n",
    "    \n",
    "    file_name_and_path = directory + \"/\" + os.listdir(directory)[random_file_number]\n",
    "    file_names_and_paths.append(file_name_and_path)\n",
    "    \n",
    "file_names_and_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import reports, collect unique words and save words not in SentiLex-PT02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of reports read to improve SentiLex database\n",
      "../programa_de_fiscalizacao_em_entes_federativos/ciclo_3/9044-Putinga-RS.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/ciclo_4/10321-Uruguaiana-RS.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/ciclo_5/12311-Teresópolis-RJ.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_34/1837-São Mateus-ES.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_35/1906-Patrocínio-MG.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_36/2483-Pontal do Paraná-PR.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_37/2871-São José do Sul-RS.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_38/2975-Presidente Kennedy-ES.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_39/3179-São Domingos do Araguaia-PA.pdf\n",
      "../programa_de_fiscalizacao_em_entes_federativos/edicoes_anteriores/sorteio_40/3390-Goianésia do Pará-PA.pdf\n"
     ]
    }
   ],
   "source": [
    "print(\"List of reports read to improve SentiLex database\")\n",
    "\n",
    "words_without_polarity_full = pd.DataFrame(columns=['adjective', 'polarity'])\n",
    "\n",
    "for file_number in range(0, len(file_names_and_paths)):\n",
    "    \n",
    "    file_name = file_names_and_paths[file_number]\n",
    "    print(file_name)\n",
    "    \n",
    "    # create a pdf object\n",
    "    file = open(file_name, 'rb')\n",
    "    \n",
    "    # create a pdf reader object\n",
    "    file_reader = PyPDF2.PdfFileReader(file)\n",
    "\n",
    "    # iterate all documents\n",
    "    word_index = -1\n",
    "    flag_in_a_word = 0\n",
    "    words = []\n",
    "\n",
    "    for i in range(file_reader.numPages):\n",
    "        page = unidecode.unidecode(file_reader.getPage(i).extractText().lower())\n",
    "\n",
    "        for j in range(len(page)):\n",
    "            letter = page[j]\n",
    "\n",
    "            if (not letter.isalpha()) and flag_in_a_word != 0:\n",
    "                flag_in_a_word = 0\n",
    "            elif letter.isalpha() and flag_in_a_word == 0:\n",
    "                flag_in_a_word = 1\n",
    "                word_index += 1\n",
    "                words.append(letter)\n",
    "            elif letter.isalpha() and flag_in_a_word != 0:\n",
    "                words[word_index] += letter\n",
    "\n",
    "    words_unique = pd.DataFrame(pd.DataFrame(words).iloc[:, 0].unique())\n",
    "    words_unique.columns = [\"adjective\"]\n",
    "    \n",
    "    words_with_polarity = words_unique.merge(sentilex_database,\n",
    "                                             left_on=\"adjective\",\n",
    "                                             right_on=\"adjective\",\n",
    "                                             how=\"left\")\n",
    "    \n",
    "    words_without_polarity_full = pd.concat([words_without_polarity_full,\n",
    "                                             words_with_polarity[words_with_polarity.polarity.isnull()]])\n",
    "\n",
    "\n",
    "words_without_polarity_full = pd.DataFrame(words_without_polarity_full.adjective.unique())\n",
    "words_without_polarity_full.columns = ['adjective']\n",
    "words_without_polarity_full['polarity'] = ''\n",
    "\n",
    "words_without_polarity_full.sort_values(by=['adjective'], inplace=True)\n",
    "\n",
    "words_without_polarity_full.to_csv(\"improving_sentilex/99_create_improving_sentilex.csv\",\n",
    "                                   sep=';',\n",
    "                                   encoding='utf-8',\n",
    "                                   index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
