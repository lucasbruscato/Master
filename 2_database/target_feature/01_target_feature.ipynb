{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Target Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import csv\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lists with all paths to all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: \n",
      "../programa_de_fiscalizacao_em_entes_federativos/ciclo_3/8998-Santo Antônio de Jesus-BA.pdf\n"
     ]
    }
   ],
   "source": [
    "folders = [\"ciclo_3\",\n",
    "           \"ciclo_4\",\n",
    "           \"ciclo_5\",\n",
    "           \"edicoes_anteriores/sorteio_34\",\n",
    "           \"edicoes_anteriores/sorteio_35\",\n",
    "           \"edicoes_anteriores/sorteio_36\",\n",
    "           \"edicoes_anteriores/sorteio_37\",\n",
    "           \"edicoes_anteriores/sorteio_38\",\n",
    "           \"edicoes_anteriores/sorteio_39\",\n",
    "           \"edicoes_anteriores/sorteio_40\"]\n",
    "\n",
    "seq_folders = []\n",
    "file_names = []\n",
    "file_names_and_paths = []\n",
    "\n",
    "for folder in folders:\n",
    "    directory = '../programa_de_fiscalizacao_em_entes_federativos/' + folder\n",
    "    \n",
    "    number_of_files = len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
    "    \n",
    "    for i in range(0, number_of_files):\n",
    "        file_name_and_path = directory + \"/\" + os.listdir(directory)[i]\n",
    "        if (\".pdf\" in file_name_and_path):\n",
    "            seq_folders.append(folder)\n",
    "            file_names.append(os.listdir(directory)[i])\n",
    "            file_names_and_paths.append(file_name_and_path)\n",
    "\n",
    "print('Example: \\n' + file_names_and_paths[0:1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate target feature for each report ('read' and summarised the polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentilex_database = pd.read_csv(\"../sentilex/99_01_sentilex_database.csv\",\n",
    "                                sep = \";\")\n",
    "\n",
    "sentilex_database.adjective = sentilex_database.adjective.str.normalize('NFKD').\\\n",
    "                                str.encode('ascii', errors='ignore').str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_and_paths = ['../programa_de_fiscalizacao_em_entes_federativos/ciclo_3/8998-Santo Antônio de Jesus-BA.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of reports read and summarised\n",
      "2019-08-02 21:48:31.160329 ../programa_de_fiscalizacao_em_entes_federativos/ciclo_3/8998-Santo Antônio de Jesus-BA.pdf\n"
     ]
    }
   ],
   "source": [
    "cities = pd.DataFrame()\n",
    "\n",
    "print(\"List of reports read and summarised\")\n",
    "\n",
    "for file_number in range(0, len(file_names_and_paths)):\n",
    "    folder = seq_folders[file_number]\n",
    "    file_name = file_names[file_number]\n",
    "    file_name_and_path = file_names_and_paths[file_number]\n",
    "    print(str(datetime.datetime.now()) + ' ' + file_name_and_path)\n",
    "    \n",
    "    # read report using external library pdf miner and save in 'temp_report.txt'\n",
    "    command_to_cmd = 'pdf2txt.py \"' + file_name_and_path + '\" > temp_report.txt'\n",
    "    os.system(command_to_cmd)\n",
    "    \n",
    "    # read temporary file\n",
    "    temporary_file = open('temp_report.txt', 'r')\n",
    "    \n",
    "    whole_text = ''\n",
    "    \n",
    "    for line in temporary_file:\n",
    "        whole_text += line\n",
    "    \n",
    "    words = re.findall(r\"[\\w']+\", unidecode.unidecode(re.sub('\\d', ' ', whole_text).lower()))\n",
    "\n",
    "    # create the frequencies\n",
    "    words_freq = pd.DataFrame.from_dict(Counter(words), orient = 'index').reset_index()\n",
    "    words_freq.columns = ['word', 'freq']\n",
    "    words_freq['pct'] = words_freq['freq']/sum(words_freq.freq)\n",
    "\n",
    "    # aggregate polarity\n",
    "    words_freq_polarity = words_freq.merge(sentilex_database,\n",
    "                                           left_on = \"word\",\n",
    "                                           right_on = \"adjective\",\n",
    "                                           how = \"left\").iloc[:, [0, 1, 2, 4]]\n",
    "    \n",
    "    # summarise\n",
    "    number_of_words = words_freq_polarity.freq.sum()\n",
    "    pct_pol_neg = words_freq_polarity[words_freq_polarity.polarity == -1].pct.sum()\n",
    "    pct_pol_pos = words_freq_polarity[words_freq_polarity.polarity == 1].pct.sum()\n",
    "    pct_pol_neu = words_freq_polarity[words_freq_polarity.polarity == 0].pct.sum()\n",
    "    pct_pol_missing = words_freq_polarity[words_freq_polarity.polarity.isna()].pct.sum()\n",
    "\n",
    "    current_city = pd.DataFrame({\"folder\": folder,\n",
    "                                 \"file_name\": file_name,\n",
    "                                 \"number_of_words\": number_of_words,\n",
    "                                 \"pct_pol_neg\": pct_pol_neg,\n",
    "                                 \"pct_pol_pos\": pct_pol_pos,\n",
    "                                 \"pct_pol_neu\": pct_pol_neu,\n",
    "                                 \"pct_pol_missing\": pct_pol_missing},\n",
    "                                index = [0])\n",
    "\n",
    "    cities = cities.append(current_city)    \n",
    "    \n",
    "    # save last words_freq_polarity dataframe as an example\n",
    "    if file_number + 1 == len(file_names_and_paths):\n",
    "        words_freq_polarity.to_csv('temp_words_freq_polarity.csv',\n",
    "                                   sep=';',\n",
    "                                   encoding='utf-8',\n",
    "                                   index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"temp_report.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.to_csv(\"../target_feature/01_target_feature.csv\",\n",
    "              sep=';',\n",
    "              encoding='utf-8',\n",
    "              index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
