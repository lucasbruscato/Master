
\label{ape:model_training}
\hypertarget{model-training}{%
\section{Model Training}\label{model-training}}

\begin{lstlisting}[language=Python]
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
import numpy as np
import re
import datetime
from numpy import inf
from scipy.stats import randint as sp_randint
from scipy.stats import uniform as sp_randFloat
import pickle
import shap
import warnings
warnings.simplefilter('ignore')

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn import model_selection
from sklearn.model_selection import RandomizedSearchCV

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
\end{lstlisting}

\begin{lstlisting}[language=Python]
training_dataset = pd.read_csv('../2_database/data_processing/02_03_training_dataset.csv',
                               sep=';')

validation_dataset = pd.read_csv('../2_database/data_processing/02_03_validation_dataset.csv',
                                 sep=';')
\end{lstlisting}

\begin{lstlisting}[language=Python]
print("Training and Validation size: " + str(training_dataset.shape) + " / " + str(validation_dataset.shape))
\end{lstlisting}

\begin{lstlisting}
Training and Validation size: (420, 53) / (140, 53)
\end{lstlisting}

\begin{lstlisting}[language=Python]
training_dataset.head()
\end{lstlisting}

\begin{lstlisting}[language=Python]
for col in training_dataset.columns:
    print(col)
\end{lstlisting}

\begin{lstlisting}[language=Python]
array = training_dataset.values

X_training = array[:, 1:]
Y_training = array[:, 0]
\end{lstlisting}

\begin{lstlisting}[language=Python]
array = validation_dataset.values

X_validation = array[:, 1:]
Y_validation = array[:, 0]
\end{lstlisting}

\hypertarget{function-for-regression-evaluation}{%
\subsubsection{Function for regression
evaluation}\label{function-for-regression-evaluation}}

\begin{lstlisting}[language=Python]
def regression_evaluation(Y_training, y_training_pred, Y_validation, y_validation_pred):
    
    random_simulation = np.random.randint(int(np.quantile(Y_training, 0)*10), int(np.quantile(Y_training, 1)*10), size=len(Y_validation)) * 0.1
    null_simulation = [np.mean(Y_training)] * len(Y_validation)
    
    print(
        "RMSE training: " + str(np.round(np.sqrt(mean_squared_error(Y_training, y_training_pred)), 4)) + "\n" +
        "RMSE validation: " + str(np.round(np.sqrt(mean_squared_error(Y_validation, y_validation_pred)), 4)) + "\n" + 
        "RMSE validation random model: " + str(np.round(np.sqrt(mean_squared_error(Y_validation, random_simulation)), 4)) + "\n" +
        "RMSE validation null model: " + str(np.round(np.sqrt(mean_squared_error(Y_validation, null_simulation)), 4))
    )

    print("\n")
    
    delta = 0.15
    
    overestimate_training_rate = np.round(sum((y_training_pred > Y_training * (1 + delta)) == True)/len(Y_training), 4)
    underestimate_training_rate = np.round(sum((y_training_pred < Y_training * (1 - delta)) == True)/len(Y_training), 4)
    wellestimate_training_rate = np.round(1-(overestimate_training_rate + underestimate_training_rate), 4)
    
    overestimate_validation_rate = np.round(sum((y_validation_pred > Y_validation * (1 + delta)) == True)/len(Y_validation), 4)
    underestimate_validation_rate = np.round(sum((y_validation_pred < Y_validation * (1 - delta)) == True)/len(Y_validation), 4)
    wellestimate_validation_rate = np.round(1-(overestimate_validation_rate + underestimate_validation_rate), 4)
    
    overestimate_random_rate = np.round(sum((random_simulation > Y_validation * (1 + delta)) == True)/len(Y_validation), 4)
    underestimate_random_rate = np.round(sum((random_simulation < Y_validation * (1 - delta)) == True)/len(Y_validation), 4)
    wellestimate_random_rate = np.round(1-(overestimate_random_rate + underestimate_random_rate), 4)
    
    overestimate_null_rate = np.round(sum((null_simulation > Y_validation * (1 + delta)) == True)/len(Y_validation), 4)
    underestimate_null_rate = np.round(sum((null_simulation < Y_validation * (1 - delta)) == True)/len(Y_validation), 4)
    wellestimate_null_rate = np.round(1-(overestimate_null_rate + underestimate_null_rate), 4)
    
    print(
        "BANDS training (underestimate | well | overestimate): " + str(underestimate_training_rate) + " | " + str(wellestimate_training_rate) + " | " + str(overestimate_training_rate) + "\n" + 
        "BANDS validation (underestimate | well | overestimate): " + str(underestimate_validation_rate) + " | " + str(wellestimate_validation_rate) + " | " + str(overestimate_validation_rate) + "\n" + 
        "BANDS validation random model (underestimate | well | overestimate): " + str(underestimate_random_rate) + " | " + str(wellestimate_random_rate) + " | " + str(overestimate_random_rate) + "\n" + 
        "BANDS validation null model (underestimate | well | overestimate): " + str(underestimate_null_rate) + " | " + str(wellestimate_null_rate) + " | " + str(overestimate_null_rate)
    )
    
    figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')
    
    plt.plot([0, 1], [0, 1], 'k-', zorder=1)
    plt.scatter(Y_training, y_training_pred, label='training', zorder=2)
    plt.scatter(Y_validation, y_validation_pred, label='validation', zorder=3)
    
    plt.ylabel("predicted")
    plt.xlabel("observed")
    plt.xlim([0, 0.75])
    plt.ylim([0, 0.75])
    
    plt.legend()
\end{lstlisting}

\hypertarget{function-for-printing-shapley-value-importance}{%
\subsubsection{Function for printing shapley value
importance}\label{function-for-printing-shapley-value-importance}}

\begin{lstlisting}[language=Python]
def print_shapley_value_importance(model, X_matrix, feature_names):
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X_matrix)
    
    shap.summary_plot(shap_values,
                      X_matrix,
                      feature_names=feature_names)
\end{lstlisting}

\hypertarget{linear-regression}{%
\subsubsection{1 - Linear Regression}\label{linear-regression}}

\begin{lstlisting}[language=Python]
linear_regression_model = LinearRegression()
linear_regression_model.fit(X_training, Y_training)

y_training_pred = linear_regression_model.predict(X_training)
y_validation_pred = linear_regression_model.predict(X_validation)
\end{lstlisting}

\begin{lstlisting}[language=Python]
linear_regression_model = pickle.load(open('03_02_linear_regression_model.pickle', 'rb'))

y_training_pred = linear_regression_model.predict(X_training)
y_validation_pred = linear_regression_model.predict(X_validation)
\end{lstlisting}

\begin{lstlisting}[language=Python]
regression_evaluation(Y_training,
                      y_training_pred,
                      Y_validation,
                      y_validation_pred)
\end{lstlisting}

\begin{lstlisting}[language=Python]
pickle.dump(linear_regression_model, open('03_02_linear_regression_model.pickle', 'wb'))
\end{lstlisting}

\begin{lstlisting}[language=Python]
linear_regression_model = pickle.load(open('03_02_linear_regression_model.pickle', 'rb'))
\end{lstlisting}

\begin{lstlisting}[language=Python]
i=0

for column_name in training_dataset.columns[1:]:
    print(column_name + " : " + str(linear_regression_model.coef_[i]))
    i = i+1
\end{lstlisting}

\hypertarget{random-forest}{%
\subsubsection{2 - Random Forest}\label{random-forest}}

\begin{lstlisting}[language=Python]
random_forest_model = RandomForestRegressor(random_state=7)

params = {'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],
          'max_features': sp_randint(5, len(training_dataset.columns)-1),
          'min_samples_split': sp_randFloat(0.1, 0.8),
          'min_samples_leaf': sp_randFloat(0.05, 0.4),
          'n_estimators': [10, 25, 50, 75, 100],
          'bootstrap': [True, False],
          'criterion': ['mse']}

rs_random_forest_model = RandomizedSearchCV(
    random_forest_model,
    param_distributions=params,
    n_iter=300,
    cv=5,
    iid=False,
    refit=True,
    random_state=7)

rs_random_forest_model.fit(X_training, Y_training)

y_training_pred = rs_random_forest_model.predict(X_training)
y_validation_pred = rs_random_forest_model.predict(X_validation)
\end{lstlisting}

\begin{lstlisting}[language=Python]
rs_random_forest_model = pickle.load(open('03_02_rs_random_forest_model.pickle', 'rb'))

y_training_pred = rs_random_forest_model.predict(X_training)
y_validation_pred = rs_random_forest_model.predict(X_validation)
\end{lstlisting}

\begin{lstlisting}[language=Python]
regression_evaluation(Y_training,
                      y_training_pred,
                      Y_validation,
                      y_validation_pred)
\end{lstlisting}

\begin{lstlisting}[language=Python]
pickle.dump(rs_random_forest_model, open('03_02_rs_random_forest_model.pickle', 'wb'))
\end{lstlisting}

\begin{lstlisting}[language=Python]
rs_random_forest_model = pickle.load(open('03_02_rs_random_forest_model.pickle', 'rb'))
\end{lstlisting}

\begin{lstlisting}[language=Python]
rs_random_forest_model.best_params_
\end{lstlisting}

\begin{lstlisting}[language=Python]
random_forest_model = RandomForestRegressor(
    bootstrap=False,
    criterion='mse',
    max_depth=10,
    max_features=13,
    min_samples_leaf=0.05170415106602393,
    min_samples_split=0.4774005510811298,
    n_estimators=75,
    random_state=7)

random_forest_model.fit(X_training, Y_training)
\end{lstlisting}

\begin{lstlisting}[language=Python]
print_shapley_value_importance(random_forest_model,
                               X_validation,
                               training_dataset.columns[1:])
\end{lstlisting}

\hypertarget{xgboost}{%
\subsubsection{3 - XGBoost}\label{xgboost}}

\begin{lstlisting}[language=Python]
xgboost_model = XGBRegressor(random_state=7)

params = {'silent': [False],
          'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],
          'learning_rate': [0.001, 0.01, 0.1, 1],
          'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
          'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
          'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],
          'gamma': [0, 0.25, 0.5, 1.0],
          'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],
          'n_estimators': [10, 25, 50, 75, 100],
          'eval_metric': ['rmse']}

rs_xgboost_model = RandomizedSearchCV(xgboost_model,
                                      param_distributions=params,
                                      n_iter=300,
                                      cv=5,
                                      iid=False,
                                      refit=True,
                                      random_state=7)

rs_xgboost_model.fit(X_training, Y_training)

y_training_pred = rs_xgboost_model.predict(X_training)
y_validation_pred = rs_xgboost_model.predict(X_validation)
\end{lstlisting}

\begin{lstlisting}[language=Python]
rs_xgboost_model = pickle.load(open('03_02_rs_xgboost_model.pickle', 'rb'))

y_training_pred = rs_xgboost_model.predict(X_training)
y_validation_pred = rs_xgboost_model.predict(X_validation)
\end{lstlisting}

\begin{lstlisting}[language=Python]
regression_evaluation(Y_training,
                      y_training_pred,
                      Y_validation,
                      y_validation_pred)
\end{lstlisting}

\begin{lstlisting}[language=Python]
pickle.dump(rs_xgboost_model, open('03_02_rs_xgboost_model.pickle', 'wb'))
\end{lstlisting}

\begin{lstlisting}[language=Python]
rs_xgboost_model = pickle.load(open('03_02_rs_xgboost_model.pickle', 'rb'))
\end{lstlisting}

\begin{lstlisting}[language=Python]
rs_xgboost_model.best_params_
\end{lstlisting}

\begin{lstlisting}[language=Python]
xgboost_model = XGBRegressor(silent=False,
                             reg_lambda=100.0,
                             n_estimators=50,
                             min_child_weight=7.0,
                             max_depth=12,
                             learning_rate=0.1,
                             gamma=0,
                             eval_metric='rmse',
                             colsample_bytree=0.4,
                             colsample_bylevel=0.7,
                             random_state=7)

xgboost_model.fit(X_training, Y_training)
\end{lstlisting}

\begin{lstlisting}[language=Python]
print_shapley_value_importance(xgboost_model,
                               X_validation,
                               training_dataset.columns[1:])
\end{lstlisting}
