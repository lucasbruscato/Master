%% ------------------------------------------------------------------------- %%
\chapter{Contexto}
\label{cap:contexto}

Este trabalho se insere no contexto de coleta de dados estruturados e não estruturados, processamento de linguagem natural (NLP, do inglês "Natural Language Processing"), previsão de polaridade e utilização de informações socioeconômicas.

Serão utilizados os relatórios de auditoria produzidos pelo "Programa de Fiscalização de Entes Federativos" que correspondem ao período de 2011 à 2018, as informações do censo do IBGE de 2000 e 2010, as informações do ENEM (INEP) de 2000 e 2010, abordagens de NLP e aprendizado de máquina aplicadas às informações supracitadas.

Tendo como intuito garantir a total replicabilidade do trabalho, as fontes de informações foram, quase em sua completude, coletadas da internet por meio de códigos desenvolvidos neste trabalho, tornando o processo altamente automatizado. O trabalho foi construído utilizando o sistema de controle de versionamento distribuído GitHub e está disponível publicamente em \citet{GitHubLucas}, que contém os códigos criados e as informações utilizadas.

Os códigos construídos durante o desenvolvimento deste trabalho utilizaram a linguagem de programação Python (\citet{Python}), tendo como ferramenta o Notebook Jupyter (\citet{JupyterNotebook}) e norma-padrão em Python o PEP8 (\citet{PEP8}) para uma melhor leitura e compreensão dos mesmos. Os códigos desenvolvidos neste trabalho foram escritos em inglês, tanto nomenclatura de variáveis quanto comentários no código.

Foi utilizada a metodologia CRISP-DM (\citet{CRISPDM}) para entendimento, exploração, modelagem e avaliação do modelo na parte do trabalho que trata de ciência de dados, assim como sua proposta para estrutura de diretórios e nomenclatura de arquivos.

\section{Programa de Fiscalização em Entes Federativos}
\label{sec:programa_de_fiscalizacao_em_entes_federativos}

Em agosto de 2015 a Controladoria-Geral da União (CGU) iniciou um trabalho que engloba o "Programa de Fiscalização em Entes Federativos", um novo método de controle que está sendo aplicado desde então na avaliação dos recursos públicos federais repassados a estados, municípios e Distrito Federal. Essa iniciativa, que visa inibir a corrupção entre gestores de qualquer esfera da administração pública, vem sendo aplicada desde abril de 2003 e, por meio do então "Programa de Fiscalização por Sorteios Públicos", a CGU utilizava o mesmo sistema das loterias da Caixa Econômica Federal para definir, de forma isenta, as áreas a serem fiscalizadas quanto ao correto uso dos recursos públicos federais.

Nas fiscalizações, os auditores da CGU examinam contas e documentos, além de realizarem inspeção pessoal e física das obras e serviços em andamento. Durante os trabalhos, o contato com a população, diretamente ou por meio dos conselhos comunitários e outras entidades organizadas, estimula os cidadãos a participarem do controle dos recursos oriundos dos tributos que lhes são cobrados.

O programa agora possui três formas de seleção de entes: censo, matriz de vulnerabilidade e sorteios. Nesse contexto, já foram fiscalizados cerca de 2,5 mil municípios brasileiros desde 2003, englobando recursos públicos federais superiores ao montante de R\$ 30 bilhões.

Quando é utilizado o censo, a fiscalização verifica a regularidade da aplicação dos recursos em todos os entes da amostragem. Já a matriz agrega inteligência da informação, por meio da análise de indicadores, para identificar vulnerabilidades (situações locais críticas) e selecionar de forma analítica os entes a serem fiscalizados em determinada região. A metodologia de sorteios permanece aleatória, ao incorporar as ações do antigo "Programa de Fiscalização por Sorteios Públicos".

No âmbito deste trabalho serão utilizados os relatórios de auditoria realizadas no período de agosto de 2011 até junho de 2018, os quais dizem respeito aos sorteios realizados dos números 34 ao 40, que correspondem ao "Programa de Fiscalização por Sorteios Públicos", e os ciclos 3, 4 e o 5, que dizem respeito ao "Programa de Fiscalização em Entes Federativos", correspondente à 598 relatórios. Os relatórios gerados pelo programa descrito nesta seção são utilizados na criação da variável resposta do problema proposto deste trabalho. Tais relatórios já foram utilizados anteriormente em \citet{FerrazFinan2008}, contudo, em tal trabalho foi feita uma interpretação manual dos relatórios, i.e., um a um os relatórios foram interpretados por humanos e classificados caso tenha sido encontrado sinais de corrupção ou não no município em questão.

A coleta de tais relatórios foi realizada de forma automatizada (para as edições com respeito aos sorteios 34 ao 40) e manual (para as edições com respeito ao ciclo 3, ciclo 4 e ciclo 5). As decisões sobre as formas como os relatórios foram coletados teve embasamento na estrutura da página web do governo.

As edições com respeito aos sorteios 34 ao 40 estão disponíveis no site da Controladoria-Geral da União e podem ser encontrados por meio de um mecanismo de busca de relatórios. Contudo, a página do mecanismo de busca frequentemente se encontra indisponível e a consulta em si é onerosa de um ponto de vista de trabalho humano, dado que devem ser preenchidos diversos campos para se realizar a pesquisa. Portanto, foi desenvolvido um robô utilizando a biblioteca Selenium (\citet{Selenium}) da linguagem de programação Python que auxilia na manipulação de páginas web, no caso, possibilita que de uma forma automática - utilizando códigos em Python - inicie uma instância do navegador Firefox, acesse o mecanismo de busca de relatórios da Controladoria-Geral da União e realize a consulta, um a um, dos relatórios de todos os municípios em questão.

O código citado no parágrafo anterior foi escrito na linguagem de programação Python utilizando a ferramenta Notebook Jupyter e se encontra no anexo (\ref{ape:import_reports}).

As edições com respeito aos ciclos 3, 4 e 5 foram coletadas diretamente na página web por estarem disponíveis na página do programa mais facilmente.

\section{SentiLex}
\label{sec:sentilex}

A base de dados SentiLex-PT02 é considerada, ao menos no idioma português na atualidade, a mais importante fonte de informação no aspecto léxico de sentimento (ver \citet{BeckerTumitan2014}). Especificamente concebido para a análise de sentimento e opinião sobre entidades humanas em textos redigidos em português, é constituído atualmente por 7.014 lemas e 82.347 formas flexionadas.

Os adjetivos presentes na base possuem uma polaridade (polaridade de cada palavra, sendo positiva, neutra ou negativa) que foi atribuída com base num cálculo sobre as distâncias das palavras, com polaridade conhecida a priori, ligadas aos adjetivos por uma relação de sinonímia num grafo, inferido a partir de dicionários de sinônimos disponíveis para o português. Os detalhes da criação de tal trabalho podem ser encontrados em \citet{Silva2012}.

Cada palavra presente na base de dados possui sua respectiva polaridade, sendo que os valores que as polaridades podem assumir são -1, 0 e 1, representando polaridade negativa, polaridade neutra e polaridade positiva, respectivamente.

\section{Variável Resposta}
\label{sec:variavel_resposta}

Para realizar uma interpretação quantitativa sobre os relatórios coletados que foram apresentados na Seção "Programa de Fiscalização de Entes Federativos", este trabalho utiliza a base da dados SentiLex para definição de polaridade de cada uma das palavras presentes nos relatórios e, assim, criação de uma métrica para modelagem.

Foi criado um código que realiza o reconhecimento de caracteres do documento pdf onde, iterativamente utilizando regras para separadores de palavras, se concatenou caracter a caracter formando as palavras do relatório pdf. Devido a problemas enfrentados com respeito a diferentes tipos de codificação (encoding, e.g., UTF-8) dos relatórios utilizados, foi necessário a utilização da biblioteca externa em python PDF Miner (\citet{PDFMiner}) para extração das palavras. Assim, a construção de tal métrica se deu pela criação de um código em python que realiza o reconhecimento das palavras presentes em documentos pdf. Pode-se sumarizar as etapas do processo pelos seguintes passos:

\begin{enumerate}
	\item Iterativamente execute o código da biblioteca externa (PDF Miner) para cada relatório de auditoria listado na Seção "Programas de Entes Federativos" (\ref{sec:programa_de_fiscalizacao_em_entes_federativos})
	\item Sobre o texto de cada relatório remova acentuação e transforme todos os caracteres em minúsculo
	\item Calcule a frequência das palavras dentro de seu respectivo documento
	\item Utilizando a base de dados SentiLex (extraída por meio da criação de um código em python), apresentada na Seção "SentiLex" (\ref{sec:sentilex}), defina a polaridade da palavra em positiva, negativa ou neutra
	\item Realize um agrupamento sobre o produto dos passos anteriores sumarizando a frequência relativa calculada sob as polaridades definidas, i.e., o resultado é um arquivo em formato CSV com as seguintes colunas: nome do relatório, quantidade de palavras, percentual de polaridade negativa, percentual de polaridade positiva, percentual de polaridade neutra e percentual de polaridade (ou, nesse sentido, palavra) não encontrada
\end{enumerate}

Para o item 5 do processo acima, foram calculados a mediana, o mínimo, o máximo e o desvio-padrão dos percentuais de polaridade e estão apresentados na tabela abaixo.

\begin{table}[h]
\centering
\caption{Métricas de percentual de polaridade}
\label{tab:cap2_analise_descritiva}
\begin{tabular}{ccccc}
Métrica & Negativa & Positiva & Neutra & Não Encontrada \\
\hline
mediana & 1.70\% & 2.79\% & 0.74\% & 94.91\% \\
mínimo & 0.36\% & 1.49\% & 0.18\% & 92.76\% \\
máximo & 4.54\% & 4.54\% & 1.79\% & 97.04\% \\
desvio-padrão & 0.37\% & 0.35\% & 0.18\% & 0.59\% \\
\hline
\end{tabular}
\end{table}
\FloatBarrier

Os códigos citados no parágrafo anterior foram escritos na linguagem de programação Python utilizando a ferramenta Notebook Jupyter e se encontram nos anexos \ref{ape:sentilex_database} e \ref{ape:create_target_feature}, respectivamente.

O resultado da execução dos itens enumerados acima proporciona a criação da variável resposta, que é dada como sendo o percentual de palavras negativas encontradas em um relatório dividido pela soma do valor do percentual de palavras negativas e do valor do percentual de palavras positivas, ou seja, se relativiza o percentual de palavras negativas pela soma do percentual de palavras negativas e percentual de palavras positivas para, assim, facilitar a interpretação dos resultados e desconsiderar o percentual de palavras neutras e o percentual de palavras não encontradas.

O agrupamento realizado no item 5 do processo descrito para extração das métricas se assemelha à medida estatística tf-idf (term frequency–inverse document frequency, ver \citet{Jones1972}), que tem o intuito de indicar a importância de uma palavra de um documento em relação a uma coleção de documentos ou em um corpus linguístico. O valor tf–idf de uma palavra aumenta proporcionalmente à medida que aumenta o número de ocorrências dela em um documento, no entanto, esse valor é equilibrado pela frequência da palavra no corpus. Isso auxilia a distinguir o fato da ocorrência de algumas palavras serem geralmente mais comuns que outras. Contudo, devido aos relatórios terem sido coletados em diferentes anos por diferentes auditores que utilizaram-se de vocabulários e termos distintos, tal técnica não foi utilizada e a métrica calculada foi apenas a frequência dentro do próprio documento e não ponderado pelo conjunto de documentos tal como a medida estatística tf-idf.

\section{Censo do IBGE}
\label{sec:censo_do_ibge}

O censo demográfico no Brasil é uma operação censitária realizada a nível nacional a partir do ano de 1872, constitui a principal fonte de referência para o conhecimento das condições de vida da população em todos os municípios do País e em seus recortes territoriais internos, tendo como unidade de coleta a pessoa residente, na data de referência, em domicílio do Território Nacional.

O Instituto Brasileiro de Geografia e Estatística (IBGE) é o órgão responsável por realizar o censo demográfico brasileiro a partir do ano de 1940, sendo o último censo tendo sido realizado no ano de 2010 e o próximo previsto para acontecer em 2020.

O Questionário Básico da pesquisa investiga informações sobre características dos domicílios (condição de ocupação, número de banheiros, existência de sanitário, escoadouro do banheiro ou do sanitário, abastecimento de água, destino do lixo, existência de energia elétrica etc.); emigração internacional; composição dos domicílios (número de moradores, responsabilidade compartilhada, lista de moradores, identificação do responsável, relação de parentesco com o responsável pelo domicílio etc.); características do morador (sexo e idade, cor ou raça, etnia e língua falada, no caso dos indígenas, posse de registro de nascimento, alfabetização, rendimento mensal etc.); e mortalidade. A investigação nos domicílios selecionados, efetuada por meio do Questionário da Amostra, inclui, além dos quesitos presentes no Questionário Básico, outros mais detalhados sobre características do domicílio e das pessoas moradoras, bem como quesitos sobre temas específicos, como deficiência, nupcialidade e fecundidade.

A periodicidade da pesquisa é decenal, excetuando-se os anos de 1910 e 1930, em que o levantamento foi suspenso, e 1990, quando a operação foi adiada para 1991. Sua abrangência geográfica é nacional, com resultados divulgados para Brasil, Grandes Regiões, Unidades da Federação, Mesorregiões, Microrregiões, Regiões Metropolitanas, Municípios, Distritos, Subdistritos e Setores Censitários.

As informações utilizadas neste trabalho são as disponibilizadas pelos censos realizados nos anos 2000 e nos anos 2010 sob a perspectiva de comparação das informações de ambos censos. Devido à mudança na informação ou segmentação realizada em cada censo, foi realizado um mapeamento de todas as informações disponíveis por censo para definição de quais informações seriam utilizadas no trabalho (a estatística levantada no censo de 2000 pode não existir no censo de 2010, e vice-versa, ou uma segmentação diferente foi realizada em cada censo impossibilitando a comparação da informação entre ambos). Os dados coletados do IBGE são números absolutos, portanto, tais números foram divididos pelo número de habitantes do município em questão obtendo-se assim o percentual relativo pelo ano em questão. As informações que serão utilizadas estão descritas abaixo.

\begin{itemize}
	\item \verb|education_var_01_quantity_pct|: Percentual de pessoas que frequentavam creche ou escola por município em 2000 dividido pela mesma informação em 2010
	\item \verb|family_var_01_suitable_pct|: Percentual de domicílios particulares permanentes em situação adequada por município em 2000 dividido pela mesma informação em 2010
	\item \verb|family_var_01_semi_suitable_pct|: Percentual de domicílios particulares permanentes em situação semi-adequada por município em 2000 dividido pela mesma informação em 2010
	\item \verb|family_var_01_inappropriate_pct|: Percentual de domicílios particulares permanentes em situação inadequada por município em 2000 dividido pela mesma informação em 2010
	\item \verb|fertility_var_01_has_children_pct|: Percentual de mulheres de 10 anos ou mais de idade total no período de referência de 12 meses anteriores ao Censo por município em 2000 dividido pela mesma informação em 2010
	\item \verb|fertility_var_01_children_born_pct|: Percentual de mulheres de 10 anos ou mais de idade que tiveram filhos nascidos no período de referência de 12 meses anteriores ao Censo por município em 2000 dividido pela mesma informação em 2010
	\item \verb|fertility_var_01_children_borned_live_pct|: Percentual de mulheres de 10 anos ou mais de idade que tiveram filhos nascidos vivos no período de referência de 12 meses anteriores ao Censo por município em 2000 dividido pela mesma informação em 2010
	\item \verb|fertility_var_01_children_borned_dead_pct|: Percentual de mulheres de 10 anos ou mais de idade que tiveram filhos nascidos mortos no período de referência de 12 meses anteriores ao Censo por município em 2000 dividido pela mesma informação em 2010
	\item \verb|fertility_var_02_married_pct|: Percentual de pessoas de 10 anos ou mais de idade casadas por município em 2000 dividido pela mesma informação em 2010
	\item \verb|fertility_var_02_separated_pct|: Percentual de pessoas de 10 anos ou mais de idade separadas por município em 2000 dividido pela mesma informação em 2010
	\item \verb|fertility_var_02_divorced_pct|: Percentual de pessoas de 10 anos ou mais de idade divorciadas por município em 2000 dividido pela mesma informação em 2010
	\item \verb|fertility_var_02_widow_pct|: Percentual de pessoas de 10 anos ou mais de idade viúvas por município em 2000 dividido pela mesma informação em 2010
	\item \verb|fertility_var_02_single_pct|: Percentual de pessoas de 10 anos ou mais de idade solteiras por município em 2000 dividido pela mesma informação em 2010
	\item \verb|fertility_var_03_total_pct|: Percentual de pessoas de 10 anos ou mais de idade que viviam em companhia de cônjuge ou companheiro(a), por natureza da união, por município em 2000 dividido pela mesma informação em 2010
	\item \verb|work_var_01_regular_pct|: Percentual de pessoas de 10 anos ou mais de idade empregadas em situação regular por município em 2000 dividido pela mesma informação em 2010
	\item \verb|work_var_01_irregular_pct|: Percentual de pessoas de 10 anos ou mais de idade empregadas em situação irregular por município em 2000 dividido pela mesma informação em 2010
	\item \verb|social_indicator_var_01_15_to_24_years_pct|: Taxa de analfabetismo da população de 15 a 24 anos por município em 2000 dividido pela mesma informação em 2010
	\item \verb|social_indicator_var_01_25_to_59_years_pct|: Taxa de analfabetismo da população de 25 a 59 anos por município em 2000 dividido pela mesma informação em 2010
	\item \verb|social_indicator_var_01_60_to_more_years_pct|: Taxa de analfabetismo da população de 60 ou mais anos por município em 2000 dividido pela mesma informação em 2010
	\item \verb|social_indicator_var_02_suitable_pct|: Proporção de domicílios particulares permanentes em situação apropriada por município em 2000 dividido pela mesma informação em 2010
	\item \verb|social_indicator_var_02_semi_suitable_pct|: Proporção de domicílios particulares permanentes em situação semi-apropriada por município em 2000 dividido pela mesma informação em 2010
	\item \verb|social_indicator_var_02_inappropriate_pct|: Proporção de domicílios particulares permanentes em situação inapropriada por município em 2000 dividido pela mesma informação em 2010
	\item \verb|social_indicator_var_03_responsable_illiterate_pct|: Proporção de crianças de 0 a 5 anos de idade residentes em domicílios particulares permanentes com responsável ou cônjuge analfabeto por município em 2000 dividido pela mesma informação em 2010
	\item \verb|social_indicator_var_03_inappropriate_residence_pct|: Proporção de crianças de 0 a 5 anos de idade residentes em domicílios particulares permanentes com saneamento inadequado por município em 2000 dividido pela mesma informação em 2010
	\item \verb|social_indicator_var_03_responsable_illiterate_and_inapprop|\\ \verb|riate_residence_pct|: Proporção de crianças de 0 a 5 anos de idade residentes em domicílios particulares permanentese com responsável ou cônjuge analfabeto e saneamento inadequado por município em 2000 dividido pela mesma informação em 2010
\end{itemize}

Os relatórios contendo as estatísticas do censo do IBGE de 2000 e 2010 foram coletados manualmente no site do IBGE (\citet{IBGE}), contudo, foram criados dois códigos para extração estruturada da informação. O primeiro foi para organização dos diretórios dos relatórios baseado na sigla do estado, e o segundo para extração das informações das planilhas em extensão XLS (eXceL Spreadsheet) para o formato de arquivos CSV (Comma-Separated Values). A motivação para o segundo código se deve ao fato de que as planilhas originais da fonte contém formatação com layout disforme, de forma que se tornava impossível a extração direta da informação de forma simplificada.

Os códigos citados no parágrafo anterior foram escritos na linguagem de programação Python utilizando a ferramenta Notebook Jupyter e se encontram nos anexos \ref{ape:rename_folders} e \ref{ape:extract_explanatory_features}, respectivamente.

\section{Enem (INEP)}
\label{sec:enem_inep}

O Exame Nacional do Ensino Médio (Enem) é uma prova realizada pelo Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira (INEP), autarquia vinculada ao Ministério da Educação do Brasil, e foi criada em 1998. Ela é utilizada para avaliar a qualidade do ensino médio no país. Seu resultado serve para acesso ao ensino superior em universidades públicas brasileiras, através do Sistema de Seleção Unificada (SiSU), assim como em algumas universidades no exterior.

A prova também é feita por pessoas com interesse em ganhar bolsa integral ou parcial em universidade particular através do Programa Universidade para Todos (ProUni) ou para obtenção de financiamento através do Fundo de Financiamento ao Estudante do Ensino Superior (Fies). Entre 2009 e 2016 o exame serviu também como certificação de conclusão do ensino médio em cursos de Educação de Jovens e Adultos (EJA), antigo supletivo, substituindo o Exame Nacional para Certificação de Competências de Jovens e Adultos (Encceja), que voltou a ser realizado a partir de 2017. Em algumas universidades, substituiu o tradicional vestibular.

A prova foi criada em 1998, sendo usada inicialmente para avaliar a qualidade da educação nacional e já na segunda edição do exame, foi utilizada como modalidade de acesso ao ensino superior. Teve sua segunda versão iniciada em 2009, com aumento do número de questões e utilização da prova em substituição ao antigo vestibular. O exame é realizado anualmente e tem duração de dois dias, contém 180 questões objetivas (divididas em quatro grandes áreas) e uma questão de redação.

As informações utilizadas neste trabalho são as disponibilizadas pela plataforma do INEP na Seção "Microdados" (\citet{IBGE}), e foram selecionados os dados dos exames realizados em 2000 e em 2010 sob a perspectiva de comparação das informações de ambos anos. As estatísticas extraídas foram:

\begin{itemize}
	\item \verb|enem_var_01_enem_score_mean_pct|: Média da nota final do enem em 2000 dividido pela mesma informação em 2010
	\item \verb|enem_var_01_enem_score_std_pct|: Desvio-padrão da nota final do enem em 2000 dividido pela mesma informação em 2010
	\item \verb|enem_var_01_enem_score_median_pct|: Mediana da nota final do enem em 2000 dividido pela mesma informação em 2010
\end{itemize}

O código citado no parágrafo anterior foi escrito na linguagem de programação Python utilizando a ferramenta Notebook Jupyter e se encontra no anexo \ref{ape:extract_explanatory_features_enem}.

\section{Variáveis Explicativas}
\label{sec:variaveis_explicativas}

A variável que define o estado do município em questão foi utilizada como variável explicativa, contudo, foi-se necessário uma binarização da mesma utilizando um método conhecido como one-hot-encoding. O método realiza a transformação de uma variável categórica em várias variáveis numéricas, sendo que para cada categoria de tal variável é criado uma nova variável contendo o valor zero ou um, sendo que zero indica a não ocorrência de tal categoria na observação em questão e um indica a ocorrência de tal categoria na observação em questão. Tal transformação se fez necessária uma vez que os modelos de aprendizado de máquina implementados na biblioteca scikit-learn em Python não aceitam como entrada bases de dados contendo variáveis categóricas.

As variáveis extraídas do censo demográfico do IBGE dos anos 2000 e 2010 também foram utilizadas como explicativas para modelagem do problema proposto. A abordagem utilizada para tais variáveis foi utilizar as informações de modo comparativo. As variáveis do censo do IBGE que não são representadas como porcentagens foram divididas numericamente pelo tamanho populacional do município em questão, assim, se tornando porcentagens com respeito ao tamanho populacional.

Após a criação das novas variáveis conforme descrito no parágrafo anterior, todas as variáveis (tanto as variáveis criadas conforme descrição do parágrafo anterior quanto as variáveis do censo do IBGE que são representadas como porcentagens) correspondentes ao censo de 2000 foram divididas numericamente pelas variáveis de mesmo conceito correspondentes ao censo de 2010. As variáveis criadas estão na tabela abaixo e as variáveis de origem utilizadas foram descritas na Seção \ref{sec:censo_do_ibge}.

\begin{table}[h] 
\centering
\caption{Nome de todas as variáveis explicativas utilizadas}
\label{tab:cap2_todas_variaveis}
\begin{adjustbox}{height=8.0cm}
\begin{tabular}{c}
\mbox{Nome das variáveis} \\
\hline
\scriptsize \verb|education_var_01_quantity_pct| \\
\scriptsize \verb|family_var_01_suitable_pct| \\
\scriptsize \verb|family_var_01_semi_suitable_pct| \\
\scriptsize \verb|family_var_01_inappropriate_pct| \\
\scriptsize \verb|fertility_var_01_has_children_pct| \\
\scriptsize \verb|fertility_var_01_children_born_pct| \\
\scriptsize \verb|fertility_var_01_children_borned_live_pct| \\
\scriptsize \verb|fertility_var_01_children_borned_dead_pct| \\
\scriptsize \verb|fertility_var_02_married_pct| \\
\scriptsize \verb|fertility_var_02_separated_pct| \\
\scriptsize \verb|fertility_var_02_divorced_pct| \\
\scriptsize \verb|fertility_var_02_widow_pct| \\
\scriptsize \verb|fertility_var_02_single_pct| \\
\scriptsize \verb|fertility_var_03_total_pct| \\
\scriptsize \verb|work_var_01_regular_pct| \\
\scriptsize \verb|work_var_01_irregular_pct| \\
\scriptsize \verb|social_indicator_var_01_15_to_24_years_pct| \\
\scriptsize \verb|social_indicator_var_01_25_to_59_years_pct| \\
\scriptsize \verb|social_indicator_var_01_60_to_more_years_pct| \\
\scriptsize \verb|social_indicator_var_02_suitable_pct| \\
\scriptsize \verb|social_indicator_var_02_semi_suitable_pct| \\
\scriptsize \verb|social_indicator_var_02_inappropriate_pct| \\
\scriptsize \verb|social_indicator_var_03_responsable_illiterate_pct| \\
\scriptsize \verb|social_indicator_var_03_inappropriate_residence_pct| \\
\scriptsize \verb|social_indicator_var_03_responsable_illiterate_and_inappropriate_residence_pct| \\
\scriptsize \verb|enem_var_01_enem_score_mean_pct| \\
\scriptsize \verb|enem_var_01_enem_score_std_pct| \\
\scriptsize \verb|enem_var_01_enem_score_median_pct| \\
\scriptsize \verb|state_ac| \\
\scriptsize \verb|state_al| \\
\scriptsize \verb|state_ba| \\
\scriptsize \verb|state_ce| \\
\scriptsize \verb|state_es| \\
\scriptsize \verb|state_go| \\
\scriptsize \verb|state_ma| \\
\scriptsize \verb|state_mg| \\
\scriptsize \verb|state_ms| \\
\scriptsize \verb|state_mt| \\
\scriptsize \verb|state_pa| \\
\scriptsize \verb|state_pb| \\
\scriptsize \verb|state_pe| \\
\scriptsize \verb|state_pi| \\
\scriptsize \verb|state_pr| \\
\scriptsize \verb|state_rj| \\
\scriptsize \verb|state_rn| \\
\scriptsize \verb|state_ro| \\
\scriptsize \verb|state_rr| \\
\scriptsize \verb|state_rs| \\
\scriptsize \verb|state_sc| \\
\scriptsize \verb|state_se| \\
\scriptsize \verb|state_sp| \\
\scriptsize \verb|state_to| \\
\hline
\end{tabular}
\end{adjustbox}
\end{table}
\FloatBarrier

As variáveis extraídas do enem do INEP nos anos 2000 e 2010 também foram utilizadas como explicativas para modelagem do problema proposto. A abordagem utilizada para tais variáveis foi utilizar as informações de modo comparativo. As variáveis correspondentes ao exame aplicado em 2000 foram divididas numericamente pelas variáveis de mesmo conceito correspondentes ao exame aplicado em 2010. As variáveis criadas estão na tabela \ref{tab:cap2_todas_variaveis} e as variáveis brutas foram descritas na Seção \ref{sec:enem_inep}.

O código para criação das variáveis citadas nesta seção foi escrito na linguagem de programação Python utilizando a ferramenta Notebook Jupyter e se encontra no anexo \ref{ape:data_processing_modeling_dataset}.

\section{Criação da base para modelagem}
\label{sec:criacao_da_base_para_modelagem}

Utilizando como chave estrangeira a informação de munício e estado, realizou-se - por meio do código em python no anexo \ref{ape:data_processing_raw_dataset} - a união das informações citadas nas Seções "Variável Resposta" (\ref{sec:variavel_resposta}) e "Variáveis Explicativas" (\ref{sec:variaveis_explicativas}) e, assim, foram obtidas as bases para modelagem do problema proposto neste trabalho. Por meio do método de amostragem aleatória selecionou-se setenta e cinco por cento da base gerada para desenvolvimento do modelo e vinte e cinco por cento para validação do desempenho do modelo, foi-se utilizado o método de validação cruzada descrita em \citet{Kohavi1995} (amplamente aplicado em diversos trabalhos, tais como em \citet{Wesllen2017:MSc}).

O código desenvolvido para criação das bases de desenvolvimento e validação citadas no parágrafo anterior foi escrito na linguagem de programação Python utilizando a ferramenta Notebook Jupyter e se encontra no anexo \ref{ape:data_processing_training_validation_dataset}.

%% ------------------------------------------------------------------------- %%