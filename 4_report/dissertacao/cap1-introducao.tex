%% ------------------------------------------------------------------------- %%
\chapter{Introdução}
\label{cap:introducao}
O modelo de regressão normal é um dos mais utilizados na análise de variáveis aleatórias contínuas. Porém, a suposição de normalidade para os erros pode nem sempre ser a mais adequada aos dados obtidos. Mantendo a hipótese de simetria para os erros, o modelo de regressão $t$-Student tem sido proposto com o objetivo de se obter um modelo mais robusto. Com o modelo $t$-Student, podemos obter estimativas dos parâmetros menos influenciadas pela presença de dados muito distantes da média. Para saber se, de fato, nossas estimativas são menos influenciadas por observações discrepantes no modelo $t$-Student em relação ao modelo normal é preciso definir algumas medidas de influência. Dessa forma, é importante ter um método tanto para identificar uma observação como discrepante quanto aferir a influência que esta terá em nossas estimativas.

Podemos também propor modelos assimétricos. O modelo mais natural para se considerar frente ao modelo normal é o modelo normal assimétrico. A distribuição normal assimétrica foi introduzida por \citet{Azzalini1985} e estudada sob a abordagem bayesiana, por exemplo, por \citet{Bayes2005:MSc}. Ultimamente o uso da distribuição $t$-assimétrica tem sido proposto como uma alternativa robusta ao modelo de regressão normal, ver por exemplo \citet{Azzalini2008}.

A família de distribuições $t$-assimétrica é denotada por $ST(\mu,\sigsq,\nu,\lambda)$ em que $\mu$ é um parâmetro de posição, $\sigsq$ é um parâmetro de escala, $\nu$ os graus de liberdade e $\lambda$ o parâmetro de assimetria ou forma, como definido em \citet{Godoi2007:MSc}. Essa família também contempla, como casos particulares, as distribuições:
\begin{itemize}
\item Normal com média $\mu$ e variância $\sigsq$, denotada por $N(\mu,\sigsq)$. Obtida considerando $\nu \to \infty$ e $\lambda=0$;
\item $t$-Student com posição $\mu$, escala $\sigsq$ e graus de liberdade $\nu$, denotada por $t(\mu,\sigsq,\nu)$. Obtida considerando $\lambda=0$;
\item Normal assimétrica com posição $\mu$, escala $\sigsq$ e assimetria $\lambda$, denotada por \linebreak $SN(\mu,\sigsq,\lambda)$. Obtida considerando $\nu\to\infty$.
\end{itemize}
O modelo $t$-assimétrico foi introduzido em \citet{BrancoDey2001} e \citet{Azzalini2003}. Sob a abordagem bayesiana esse modelo foi estudado por \citet{Godoi2007:MSc}. Também para estes modelos temos o desafio de identificar as observações discrepantes e aferir a influência que estas terão nas estimativas dos parâmetros do modelo.

Nos modelos de regressão bayesianos uma das medidas de identificação de observações discrepantes mais conhecidas é a \textit{conditional predictive ordinate} (CPO). Baseada no método de validação de modelos \textit{leave-one-out}, esta medida avalia a função densidade de probabilidade em uma observação dadas as outras restantes.

Como medidas de influências das observações nas estimativas dos parâmetros consideraremos a família de divergências introduzidas em \citet{Weiss1996} que possui a norma $L_1$ e a divergência Kullback-Leibler como casos particulares. Também vale ressaltar que podemos medir a influência nas estimativas tanto de forma global, isto é, no vetor completo de parâmetros a serem estimados; quanto de forma marginal, em parte deste vetor de parâmetros. Ambas medidas serão consideradas neste trabalho.

%% ------------------------------------------------------------------------- %%
\section{Objetivo e Organização do Trabalho}
\label{sec:organizacao_trabalho}

O presente trabalho tem como objetivo aplicar os resultados sobre medidas de influência apresentados em \citet{Weiss1996} e estender a aplicação para o modelo de regressão normal feita em \citet{WeissCho1998}.

No segundo capítulo, abordamos os modelos de regressão linear baseados nas distribuições simétricas: normal e $t$-Student. Inicialmente, definimos as medidas de diagnóstico CPO e divergências global e marginal, aplicáveis a qualquer tipo de distribuição (não necessariamente simétrica). Para ambos modelos apresentamos como obter estimativas dos parâmetros de interesse sob o paradigma bayesiano. Mostramos também como ficam as medidas de diagnóstico para esses modelos exibindo resultados já encontrados em \citet{WeissCho1998} para o modelo normal e estendendo tais resultados para o modelo $t$-Student. Ao final do capítulo aplicamos os resultados obtidos em um conjunto de dados que exibe uma aparente normalidade mas que possui observações discrepantes.

No terceiro capítulo, exibimos resultados análogos aos obtidos no capítulo anterior para as distribuições assimétricas: normal assimétrica e $t$-assimétrica. A estimação dos parâmetros do modelo normal assimétrico utiliza os resultados obtidos em \citet{Bayes2005:MSc}. Na estimação dos parâmetros do modelo $t$-assimétrico usamos resultados obtidos em \citet{Godoi2007:MSc} e, além disso, explicitamos a forma das condicionais completas para implementação do algoritmo de Gibbs. Toda a parte de diagnóstico dos modelos é feita de forma a complementar o trabalho de \citet{WeissCho1998}. Ao final desse capítulo, aplicamos os resultados obtidos ao mesmo conjunto de dados estudado no capítulo 2, considerando algumas contaminações para verificar em que condições o modelo $t$-assimétrico realmente robustifica o modelo de regressão normal assimétrico.

No quarto capítulo, apresentamos as nossas conclusões e perspectivas para futuros trabalhos.

No apêndice, apresentamos os códigos implementados na linguagem de programação \texttt{R} para obter as estimativas e medidas de diagnóstico dos quatro modelos abordados neste trabalho.
%% ------------------------------------------------------------------------- %%
\section{Contribuições}
\label{sec:contribucoes}

A principal contribuição deste trabalho é obter as medidas de diagnóstico global e marginal calculadas para os modelos $t$-Student, normal assimétrico e $t$-assimétrico. Para tanto, fizemos toda a dedução teórica dessas medidas estendendo o trabalho de \citet{WeissCho1998} e também apresentamos como obter estimativas destas medidas por meio da integração de Monte Carlo. 

Também fizemos aqui uma adição ao trabalho de \citet{Godoi2007:MSc} exibindo as distribuições condicionais completas da distribuição $t$-Student (com os graus de liberdade fixados) possibilitando assim estruturarmos o algoritmo de Gibbs para obtenção de uma amostra da distribuição \textit{a posteriori}.

