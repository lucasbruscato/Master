%% ------------------------------------------------------------------------- %%
\chapter{Introdução}
\label{cap:introducao}

\section{Motivação}
\label{sec:motivacao}

O surgimento da corrupção está relacionado à criação das primeiras civilizações e no Brasil é um problema antigo, complexo e com origem muitas vezes atribuída aos primórdios da colonização brasileira pela coroa portuguesa (ver \citet{LeiteMacedo2017}). Durante o processo de colonização foram observados comportamentos presentes no relacionamento entre colonos e nativos que, posteriormente analisados por meio de correspondências históricas, foram classificados como corrupção conforme relatado em \citet{LeiteMacedo2017}.

É de conhecimento internacional a magnitude da corrupção no Brasil assim como suas implicações, dentre elas, pode ser citada a desigualdade social (ver \citet{Alves2018}), que por sua vez implica em criminalidade demonstrado em \citet{ResendeAndrade2018} e, assim, sucessivamente com uma extensa lista de causas e consequências.

Com a democratização da internet e a evolução da ciência de dados de um modo geral, diversos estudos estatísticos envolvendo transparência política e estudos relacionados com causa e consequência da corrupção foram possibilitados (e.g. \citet{FerrazFinan2008} e \citet{Ransom2013:MSc}). Tais estudos auxiliarão na identificação de corrupção e possivelmente em seu combate.

Em agosto de 2015 a Controladoria-Geral da União (CGU) iniciou um trabalho que engloba o "Programa de Fiscalização em Entes Federativos" (\cite{CGU}), um novo método de controle que está sendo aplicado desde então na avaliação dos recursos públicos federais repassados a estados, municípios e Distrito Federal. No "Programa de Fiscalização em Entes Federativos" houveram fiscalizações que tiveram como objetivo avaliar a aplicação dos recursos federais repassados aos municípios pelos Ministérios da Educação, Saúde e Integração Nacional, por exemplo. A seleção dos municípios a serem auditados foi feita por meio de diversas normas definidas pelo CGU sendo que anualmente foram selecionados em média sessenta municípios.

O resultado de tal trabalho governamental - o relatório de auditoria - contém informações e conclusões dos auditores sobre cada município baseado nas informações coletadas, cuja forma segue estrita observância às normas de fiscalização aplicáveis ao Serviço Público Federal (técnicas de inspeção física e registros fotográficos, análise documental, realização de entrevistas e aplicação de questionários).

Tais relatórios possuem informações que - de uma forma automatizada por meio de técnicas de aprendizado de máquina - podem ser extraídas e interpretadas como indicadores de corrupção (desvio de verba governamental), deficiência econômica ou social.

\section{Objetivo}
\label{sec:objetivo}

O presente trabalho tem como objetivo aplicar técnicas de processamento de linguagem natural para extrair a polaridade média das palavras presentes em relatórios de auditoria governamentais sobre municípios brasileiros. Utilizando-se de informações sociais sobre tais municípios, aplicar técnicas de aprendizado de máquina com o intuito de predizer a média percentual de polaridade negativa de palavras presentes em tais relatórios.

\section{Contribuições}
\label{sec:contribuicoes}

A principal contribuição deste trabalho é propor um modelo estatístico utilizando informações dos censos do IBGE e do INEP para predição de informações extraídas de relatórios de auditoria.

Para tanto, foi feita a extração das seguintes informações: os relatórios de auditoria do "Programa de Fiscalização em Entes Federativos" (utilizados no trabalho de \citet{FerrazFinan2008}), as informações do censo do IBGE (utilizadas parcialmente no trabalho de \citet{Goldani2001}) e as informações do desempenho no enem (INEP). Posteriormente, foram realizadas interpretações destes relatórios utilizando aprendizado de máquina por meio de n-gram e frequência dos termos.

Foi apresentado nesta dissertação uma adição ao trabalho de \citet{FerrazFinan2008} exibindo interpretações automatizadas sobre os relatórios que também foram utilizados pelos mesmos, de tal forma que a informação extraída pode ser replicada e utilizada por trabalhos futuros.

\section{Estrutura do Trabalho}
\label{sec:estrutura_do_trabalho}

Este trabalho é organizado em 4 capítulos e um apêndice, descritos abaixo.

O primeiro capítulo - no qual o leitor se encontra - apresenta toda a estrutura, embasamento e motivação para o trabalho.

No segundo capítulo são abordados os aspectos tecnológicos utilizados no trabalho, assim como os padrões de programação escolhidos. A forma como foram coletadas e extraídas as informações de todos os relatórios produzidos pela CGU no "Programa de Fiscalização de Entes Federativos". E, por fim, a forma como foram coletadas e criadas as bases de dados com informações coletadas dos censos do IBGE e no INEP realizados nos anos 2000 e 2010.

No terceiro capítulo são analisados os dados coletados no segundo capítulo, apresentados os métodos de avaliação de desempenho, assim como a criação de três modelos distintos (regressão linear, random forest e xgboost) para predição do mesmo.

No quarto capítulo são apresentadas as conclusões e perspectivas para trabalhos futuros.

No apêndice são apresentados os programas para obtenção dos dados, processamento dos dados, modelagem, e tabelas com informações dos dados deste trabalho.

%% ------------------------------------------------------------------------- %%